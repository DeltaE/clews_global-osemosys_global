{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSeMOSYS-PLEXOS global model: TS-dependent parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data files and user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks whether PLEXOS-World 2015 data needs to be retrieved from the PLEXOS-World Harvard Dataverse.\n",
    "try:\n",
    "    Open = open(r'data/All_Demand_UTC_2015.csv')\n",
    "    \n",
    "    demand_df = pd.read_csv(r'data/All_Demand_UTC_2015.csv' , encoding='latin-1')\n",
    "    \n",
    "except IOError:\n",
    "    urllib.request.urlretrieve ('https://dataverse.harvard.edu/api/access/datafile/3985039?format=original&gbrecs=true', \n",
    "                                r'data/All_Demand_UTC_2015.csv')\n",
    "    \n",
    "    demand_df = pd.read_csv(r'data/All_Demand_UTC_2015.csv' , encoding='latin-1')\n",
    "\n",
    "seasons_df = pd.read_csv(r'data\\ts_seasons.csv')\n",
    "dayparts_df = pd.read_csv(r'data\\ts_dayparts.csv')\n",
    "\n",
    "daytype_included = False\n",
    "model_start_year = 2015\n",
    "model_end_year = 2050\n",
    "years = list(range(model_start_year, model_end_year+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_df = pd.read_csv(r'data\\CSP 2010-2017.csv', encoding='latin-1')\n",
    "csp_df.name = 'CSP'\n",
    "\n",
    "spv_df = pd.read_csv(r'data\\SolarPV 2010-2017.csv', encoding='latin-1')\n",
    "spv_df.name = 'SPV'\n",
    "\n",
    "hyd_df = pd.read_csv(r'data\\Hydro_Monthly_Profiles (15 year average).csv', encoding='latin-1')\n",
    "hyd_df.name = 'HYD'\n",
    "\n",
    "won_df = pd.read_csv(r'data\\Won 2010-2017.csv', encoding='latin-1')\n",
    "won_df.name = 'WON'\n",
    "\n",
    "wof_df = pd.read_csv(r'data\\Woff 2010-2017.csv', encoding='latin-1')\n",
    "wof_df.name = 'WOF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 'output' directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('osemosys_global_model\\data'):\n",
    "    os.makedirs('osemosys_global_model\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create columns for year, month, day, hour, and day type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_nodes = [x for x in demand_df.columns if x != 'Datetime']\n",
    "\n",
    "# Convert datetime to year, month, day, and hour\n",
    "demand_df['Datetime'] = pd.to_datetime(demand_df['Datetime'])\n",
    "demand_df['Year'] = demand_df['Datetime'].dt.strftime('%Y').astype(int)\n",
    "demand_df['Month'] = demand_df['Datetime'].dt.strftime('%m').astype(int)\n",
    "demand_df['Day'] = demand_df['Datetime'].dt.strftime('%d').astype(int)\n",
    "demand_df['Hour'] = demand_df['Datetime'].dt.strftime('%H').astype(int)\n",
    "\n",
    "# Create column for weekday/weekend\n",
    "demand_df['Day-of-week'] = demand_df['Datetime'].dt.dayofweek\n",
    "demand_df.loc[demand_df['Day-of-week'] < 5, 'Day-of-week'] = 'WD'\n",
    "demand_df.loc[demand_df['Day-of-week'] != 'WD', 'Day-of-week'] = 'WE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries for 'seasons' and 'dayparts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_dict = dict(zip(list(seasons_df['month']),\n",
    "                        list(seasons_df['season'])\n",
    "                       )\n",
    "                   )\n",
    "\n",
    "dayparts_dict = {i: [j, k] \n",
    "                 for i, j, k \n",
    "                 in zip(list(dayparts_df['daypart']), \n",
    "                        list(dayparts_df['start_hour']), \n",
    "                        list(dayparts_df['end_hour'])\n",
    "                                             )\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create columns with 'seasons' and 'dayparts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df['Season'] = demand_df['Month']\n",
    "demand_df['Season'].replace(seasons_dict, inplace=True)\n",
    "\n",
    "for daypart in dayparts_dict:\n",
    "    demand_df.loc[(demand_df['Hour'] >= dayparts_dict[daypart][0]) &\n",
    "                  (demand_df['Hour'] < dayparts_dict[daypart][1]),\n",
    "                  'Daypart'] = daypart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create column for timeslice with and without day-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if daytype_included:\n",
    "    demand_df['TIMESLICE'] = (demand_df['Season'] +\n",
    "                              demand_df['Day-of-week'] +\n",
    "                              demand_df['Daypart'])\n",
    "else:\n",
    "    demand_df['TIMESLICE'] = (demand_df['Season'] +\n",
    "                              demand_df['Daypart'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate YearSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearsplit = (demand_df['TIMESLICE'].\n",
    "             value_counts(normalize = True).\n",
    "             to_frame('VALUE').\n",
    "             round(4).\n",
    "             reset_index().\n",
    "             rename({'index':'TIMESLICE'}, axis = 1))\n",
    "\n",
    "yearsplit_final = pd.DataFrame(list(itertools.product(yearsplit['TIMESLICE'].unique(),\n",
    "                                                      years)\n",
    "                                   ),\n",
    "                               columns = ['TIMESLICE', 'YEAR']\n",
    "                              )\n",
    "yearsplit_final = yearsplit_final.join(yearsplit.set_index('TIMESLICE'), \n",
    "                                       on = 'TIMESLICE')\n",
    "yearsplit_final.to_csv(r'osemosys_global_model\\data\\YearSplit.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate SpecifiedAnnualDemand and SpecifiedDemandProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_demand_df = demand_df[[x \n",
    "                          for x in demand_df.columns \n",
    "                          if x in demand_nodes or\n",
    "                          x == 'TIMESLICE']]\n",
    "sp_demand_df = pd.melt(sp_demand_df,\n",
    "                       id_vars = 'TIMESLICE',\n",
    "                       value_vars = demand_nodes, \n",
    "                       var_name = 'node', \n",
    "                       value_name = 'demand')\n",
    "\n",
    "sp_demand_df = sp_demand_df.groupby(['TIMESLICE', 'node'], \n",
    "                                    as_index = False).agg(sum)\n",
    "\n",
    "# Calculate SpecifiedAnnualDemand\n",
    "total_demand_df = sp_demand_df.groupby('node', \n",
    "                                       as_index = False).agg(sum)\n",
    "\n",
    "total_demand_df.rename({'demand':'total_demand'}, \n",
    "                       axis = 1, \n",
    "                       inplace = True)\n",
    "\n",
    "sp_demand_df = sp_demand_df.join(total_demand_df.set_index('node'), \n",
    "                                 on = 'node')\n",
    "\n",
    "# Calculate SpecifiedDemandProfile\n",
    "\n",
    "sp_demand_df['VALUE'] = (sp_demand_df['demand'] / \n",
    "                         sp_demand_df['total_demand'])\n",
    "\n",
    "                \n",
    "# Filter out country aggregate values for countries with multiple nodes \n",
    "country_with_nodes = list((sp_demand_df.loc[sp_demand_df['node'].str.len() > 6,\n",
    "                                       'node'].\n",
    "                      str[:-3].\n",
    "                      unique()))\n",
    "\n",
    "sp_demand_df = sp_demand_df.loc[~(sp_demand_df['node'].\n",
    "                                  isin(country_with_nodes))]\n",
    "\n",
    "\n",
    "# Rename COMMODITY based on naming convention. \n",
    "# Add 'XX' for countries without multiple nodes\n",
    "sp_demand_df.loc[sp_demand_df['node'].str.len() <= 6, \n",
    "                 'FUEL'] = ('ELC' + \n",
    "                                 sp_demand_df['node'].\n",
    "                                 str.split('-').\n",
    "                                 str[1:].\n",
    "                                 str.join(\"\") +\n",
    "                                 'XX02')\n",
    "\n",
    "sp_demand_df.loc[sp_demand_df['node'].str.len() > 6, \n",
    "                 'FUEL'] = ('ELC' + \n",
    "                                 sp_demand_df['node'].\n",
    "                                 str.split('-').\n",
    "                                 str[1:].\n",
    "                                 str.join(\"\") +\n",
    "                                 '02')\n",
    "\n",
    "# Create master table for SpecifiedDemandProfile\n",
    "sp_demand_df_final = pd.DataFrame(list(itertools.product(sp_demand_df['TIMESLICE'].unique(),\n",
    "                                                         sp_demand_df['FUEL'].unique(),\n",
    "                                                         years)\n",
    "                                      ),\n",
    "                                  columns = ['TIMESLICE', 'FUEL', 'YEAR']\n",
    "                                 )\n",
    "sp_demand_df_final = sp_demand_df_final.join(sp_demand_df.set_index(['TIMESLICE', 'FUEL']), \n",
    "                                             on = ['TIMESLICE', 'FUEL'])\n",
    "\n",
    "# Add 'REGION' column and fill 'GLOBAL' throughout\n",
    "sp_demand_df_final['REGION'] = 'GLOBAL'\n",
    "\n",
    "total_demand_df_final = (sp_demand_df_final.\n",
    "                         groupby(['REGION',\n",
    "                                  'FUEL',\n",
    "                                  'YEAR'],\n",
    "                                 as_index = False)['total_demand'].\n",
    "                         agg('mean').\n",
    "                         rename({'total_demand':'VALUE'}, \n",
    "                                axis = 1)\n",
    "                        )\n",
    "\n",
    "# Convert SpecifiedAnnualDemand to required units\n",
    "total_demand_df_final['VALUE'] = total_demand_df_final['VALUE'].mul(3.6*1e-6)\n",
    "\n",
    "# Generate SpecifiedAnnualDemand.csv file \n",
    "total_demand_df_final.to_csv(r'osemosys_global_model\\data\\SpecifiedAnnualDemand.csv', index = None)\n",
    "\n",
    "# Generate SpecifiedDemandProfile.csv file \n",
    "sp_demand_df_final = sp_demand_df_final[['REGION',\n",
    "                                         'FUEL',\n",
    "                                         'TIMESLICE',\n",
    "                                         'YEAR', \n",
    "                                         'VALUE']]\n",
    "\n",
    "sp_demand_df_final.to_csv(r'osemosys_global_model\\data\\SpecifiedDemandProfile.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CapacityFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_ts_df = demand_df[['Datetime', 'TIMESLICE']]\n",
    "capfac_all_df = pd.DataFrame(columns = ['REGION',\n",
    "                                          'TECHNOLOGY',\n",
    "                                          'TIMESLICE',\n",
    "                                          'YEAR', \n",
    "                                          'VALUE'])\n",
    "\n",
    "def capacity_factor(df):\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    capfac_df = (df.\n",
    "                 set_index('Datetime').\n",
    "                 join(datetime_ts_df.\n",
    "                      set_index('Datetime'),\n",
    "                      on = 'Datetime')\n",
    "                )\n",
    "    capfac_nodes = [x for \n",
    "                    x in \n",
    "                    capfac_df.columns \n",
    "                    if x \n",
    "                    not in ['Datetime', 'TIMESLICE']]\n",
    "    capfac_df = capfac_df.reset_index().drop('Datetime', \n",
    "                                             axis = 1)\n",
    "    capfac_df = pd.melt(capfac_df,\n",
    "                        id_vars = 'TIMESLICE',\n",
    "                        value_vars = capfac_nodes, \n",
    "                        var_name = 'node', \n",
    "                        value_name = 'VALUE')\n",
    "    capfac_df = (capfac_df.\n",
    "                 groupby(['TIMESLICE', 'node'],\n",
    "                         as_index = False).\n",
    "                 agg('mean')\n",
    "                )\n",
    "    capfac_df['VALUE'] = (capfac_df['VALUE'].\n",
    "                          div(100).\n",
    "                          round(4)\n",
    "                         )\n",
    "    \n",
    "    ## Filter out country aggregate values for countries with multiple nodes \n",
    "    capfac_df = capfac_df.loc[~(capfac_df['node'].\n",
    "                                isin(country_with_nodes))]\n",
    "\n",
    "    # Rename COMMODITY based on naming convention. \n",
    "    # Add 'XX' for countries without multiple nodes\n",
    "    capfac_df.loc[capfac_df['node'].str.len() <= 6, \n",
    "                  'TECHNOLOGY'] = ('PWR' +\n",
    "                                   df.name +\n",
    "                                   capfac_df['node'].\n",
    "                                   str.split('-').\n",
    "                                   str[1:].\n",
    "                                   str.join(\"\") +\n",
    "                                   'XX01')\n",
    "    \n",
    "    capfac_df.loc[capfac_df['node'].str.len() > 6, \n",
    "                  'TECHNOLOGY'] = ('PWR' + \n",
    "                                   df.name +\n",
    "                                   capfac_df['node'].\n",
    "                                   str.split('-').\n",
    "                                   str[1:].\n",
    "                                   str.join(\"\") +\n",
    "                                   '01')\n",
    "    \n",
    "    # Create master table for SpecifiedDemandProfile\n",
    "    capfac_df_final = pd.DataFrame(list(itertools.product(capfac_df['TIMESLICE'].unique(),\n",
    "                                                          capfac_df['TECHNOLOGY'].unique(),\n",
    "                                                          years)\n",
    "                                      ),\n",
    "                                   columns = ['TIMESLICE', 'TECHNOLOGY', 'YEAR']\n",
    "                                 )\n",
    "    capfac_df_final = (capfac_df_final.\n",
    "                       join(capfac_df.\n",
    "                            set_index(['TIMESLICE', 'TECHNOLOGY']), \n",
    "                            on = ['TIMESLICE', 'TECHNOLOGY'])\n",
    "                      )\n",
    "    \n",
    "    # Add 'REGION' column and fill 'GLOBAL' throughout\n",
    "    capfac_df_final['REGION'] = 'GLOBAL'\n",
    "    \n",
    "    capfac_df_final = capfac_df_final[['REGION',\n",
    "                                       'TECHNOLOGY',\n",
    "                                       'TIMESLICE',\n",
    "                                       'YEAR', \n",
    "                                       'VALUE']]\n",
    "    \n",
    "    return capfac_df_final\n",
    "\n",
    "\n",
    "for each in [csp_df, spv_df, won_df, wof_df]:\n",
    "    capfac_all_df = capfac_all_df.append(capacity_factor(each),\n",
    "                                         ignore_index = True)\n",
    "    \n",
    "capfac_all_df.to_csv(r'osemosys_global_model\\data\\CapacityFactor.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create csv for TIMESLICE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice_list = list(demand_df['TIMESLICE'].unique())\n",
    "time_slice_df = pd.DataFrame(time_slice_list, columns = ['VALUE'])\n",
    "time_slice_df.to_csv(r'osemosys_global_model\\data\\TIMESLICE.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
