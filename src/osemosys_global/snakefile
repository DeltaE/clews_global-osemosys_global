import os
#import pandas as pd

#####################################
## HELPER FUNCTIONS
#####################################

def fileCheckFunc(csvFiles):
	# DEFENITION: Checks what files will need to be created via OPG_filecheck.py
	# INPUT:      csvFiles = List of all otoole osemosys csv's
	# OUTPUT:     csvFiles = List of all files that need to be created via OPG_filecheck 

	if not os.path.exists(outputDir + 'data/'):
		os.makedirs(outputDir + 'data/')
	
	for each_csv in os.listdir(outputDir + 'data/'):
		if each_csv in csvFiles:
			csvFiles.remove(each_csv)
	
	return csvFiles

def getDataFiles(csvPath):
	# DEFENITION: Gets list of all data files otoole needs to run 
	# INPUT:      csvPath = path to *.csv file that has all the names of the files
	# OUTPUT:     dataFiles = list containing strings of all files needed
	
	df = pd.read_csv(csvPath)
	#dataFiles = df['file_name'].tolist()
	#return dataFiles

#####################################
## REQUIRED FILES 
#####################################

#osemosysFiles = getDataFiles('../../data/csv_file_list.csv')
osemosysFiles = [
	'AccumulatedAnnualDemand.csv',
	'AnnualEmissionLimit.csv',
	'AnnualExogenousEmission.csv',
	'AvailabilityFactor.csv',
	'CapacityFactor.csv',
	'CapacityOfOneTechnologyUnit.csv',
	'CapacityToActivityUnit.csv',
	'CapitalCost.csv',
	'CapitalCostStorage.csv',
	'Conversionld.csv',
	'Conversionlh.csv',
	'Conversionls.csv',
	'DAILYTIMEBRACKET.csv',
	'DaysInDayType.csv',
	'DaySplit.csv',
	'DAYTYPE.csv',
	#'default_values.csv',
	'DepreciationMethod.csv',
	'DiscountRate.csv',
	'DiscountRateStorage.csv',
	'EMISSION.csv',
	'EmissionActivityRatio.csv',
	'FixedCost.csv',
	'FUEL.csv',
	'InputActivityRatio.csv',
	'MinStorageCharge.csv',
	'MODE_OF_OPERATION.csv',
	'ModelPeriodEmissionLimit.csv',
	'ModelPeriodExogenousEmission.csv',
	'OutputActivityRatio.csv',
	'OperationalLife.csv',
	'REMinProductionTarget.csv',
	'REGION.csv',
	'ReserveMargin.csv',
	'ReserveMarginTagFuel.csv',
	'ReserveMarginTagTechnology.csv',
	'ResidualCapacity.csv',
	'ResidualStorageCapacity.csv',
	'RETagFuel.csv',
	'RETagTechnology.csv',
	'SEASON.csv',
	'SpecifiedAnnualDemand.csv',
	'SpecifiedDemandProfile.csv',
	'STORAGE.csv',
	'StorageLevelStart.csv',
	'StorageMaxChargeRate.csv',
	'StorageMaxDischargeRate.csv',
	'TECHNOLOGY.csv',
	'TechnologyFromStorage.csv',
	'TechnologyToStorage.csv',
	'TIMESLICE.csv',
	'TotalAnnualMaxCapacity.csv',
	'TotalAnnualMaxCapacityInvestment.csv',
	'TotalAnnualMinCapacity.csv',
	'TotalAnnualMinCapacityInvestment.csv',
	'TotalTechnologyAnnualActivityLowerLimit.csv',
	'TotalTechnologyAnnualActivityUpperLimit.csv',
	'TotalTechnologyModelPeriodActivityLowerLimit.csv',
	'TotalTechnologyModelPeriodActivityUpperLimit.csv',
	'TradeRoute.csv',
	'VariableCost.csv',
	'YEAR.csv',
	'YearSplit.csv'
]

resultFiles = [
	'AccumulatedNewCapacity.csv',
	'AnnualEmissions.csv',
	'AnnualFixedOperatingCost.csv',
	'AnnualTechnologyEmission.csv',
	'AnnualTechnologyEmissionByMode.csv',
	'AnnualVariableOperatingCost.csv',
	'CapitalInvestment.csv',
	'Demand.csv',
	'DiscountedTechnologyEmissionsPenalty.csv',
	'NewCapacity.csv',
	'ProductionByTechnology.csv',
	'ProductionByTechnologyAnnual.csv',
	'RateOfActivity.csv',
	'RateOfProductionByTechnology.csv',
	'RateOfProductionByTechnologyByMode.csv',
	'RateOfUseByTechnology.csv',
	'RateOfUseByTechnologyByMode.csv',
	'TotalAnnualTechnologyActivityByMode.csv',
	'TotalCapacityAnnual.csv',
	'TotalTechnologyAnnualActivity.csv',
	'TotalTechnologyModelPeriodActivity.csv',
	'UseByTechnology.csv'
]
	
demandFigures = [
	'South America', 
	'Oceania', 
	'North America', 
	'Europe', 
	'Asia', 
	'Africa'
]

resultFigures = [
	'TotalCapacityAnnual', 
	'GenerationAnnual',
]

#####################################
## GLOABL VARIABLES
#####################################

#get user values from configuration file 										 
configfile: 'config.yaml'
modelName = config['modelName']
inputDir = config['inputDir']
outputDir = config['outputDir']
scenarioName = config['scenario']

#directory for saving otoole formatted resutls 											   
outputFolder = directory(outputDir + scenarioName + '/results/')

ruleorder: 
	PowerPlant > 
	TimeSlice > 
	VariableCosts > 
	DemandProjections > 
	FileCheck >
	GeographicFilter 

#####################################
## TARGETS
#####################################

rule all:
	input: 
		expand(outputDir + scenarioName + '/results/{resultFile}', resultFile = resultFiles)

rule dataFile:
	input:
		expand(outputDir + 'figs/Demand projection {demandFigure}.jpg', demandFigure = demandFigures),
		outputDir + scenarioName + '/' + scenarioName + '.txt'

rule lpFile:
	input: 
		outputDir + scenarioName + '/' + scenarioName + '.lp',

rule solve:
	input: 
		expand(outputDir + scenarioName + '/figures/{resultFigure}.html', resultFigure = resultFigures)

rule makeDag:
	shell:
		'snakemake --dag solve | dot -Tpdf > dag.pdf'

#####################################
## INTERMEDIATE RULES
#####################################

rule PowerPlant:
	input:
		inputDir + 'PLEXOS_World_2015_Gold_V1.1.xlsx',
		inputDir + 'weo_2018_powerplant_costs.csv',
		inputDir + 'operational_life.csv',
		inputDir + 'naming_convention_tech.csv',
		inputDir + 'Costs Line expansion.xlsx',
		inputDir + 'weo_region_mapping.csv',
		'config.yaml'
	output:
		outputDir + 'data/CapitalCost.csv',
		outputDir + 'data/EMISSION.csv',
		outputDir + 'data/FixedCost.csv',
		outputDir + 'data/FUEL.csv',
		outputDir + 'data/InputActivityRatio.csv',
		outputDir + 'data/MODE_OF_OPERATION.csv',
		outputDir + 'data/OutputActivityRatio.csv',
		outputDir + 'data/REGION.csv',
		outputDir + 'data/ResidualCapacity.csv',
		outputDir + 'data/TECHNOLOGY.csv',
		outputDir + 'data/YEAR.csv',
	conda:
		'envs/powerPlant.yaml'
	log:
		'logs/PowerPlant.log'
	shell:
		'python OPG_powerplant_data.py 2> {log}'
		
rule TimeSlice:
	input:
		inputDir + 'All_Demand_UTC_2015.csv',
		inputDir + 'CSP 2015.csv',
		inputDir + 'SolarPV 2015.csv',
		inputDir + 'Hydro_Monthly_Profiles (15 year average).csv',
		inputDir + 'Won 2015.csv',
		inputDir + 'Woff 2015.csv',
		'config.yaml'
	output:
		outputDir + 'data/CapacityFactor.csv',
		outputDir + 'data/TIMESLICE.csv',
		outputDir + 'data/SpecifiedDemandProfile.csv',
		outputDir + 'data/YearSplit.csv'
	conda:
		'envs/timeSlice.yaml'
	log:
		'logs/timeSlice.log'	
	shell:
		'python OPG_TS_data.py 2> {log}'

rule VariableCosts:
	input:
		inputDir + 'CMO-April-2020-forecasts.xlsx',
		outputDir + 'data/TECHNOLOGY.csv',
		'config.yaml'
	output:
		outputDir + 'data/VariableCost.csv'
	conda:
		'envs/variableCosts.yaml'
	log:
		'logs/variableCosts.log'
	shell:
		'python OPG_variablecosts.py 2> {log}'
		
rule DemandProjections:
	input:
		inputDir + 'PLEXOS_World_2015_Gold_V1.1.xlsx',
		inputDir + 'iamc_db_GDPppp_Countries.xlsx',
		inputDir + 'iamc_db_POP_Countries.xlsx',
		inputDir + 'iamc_db_URB_Countries.xlsx',
		inputDir + 'iamc_db_POP_GDPppp_URB_Countries_Missing.xlsx',
		inputDir + 'T&D Losses.xlsx',
		'config.yaml'
	output:
		expand(outputDir + 'figs/Demand projection {demandFigure}.jpg', demandFigure = demandFigures),
		outputDir + 'data/SpecifiedAnnualDemand.csv'
	conda:
		'envs/demand.yaml'
	log:
		'logs/demandProjections.log'
	shell:
		'python OPG_demand_projection.py 2> {log}'
		
rule GeographicFilter:
	input: 
		expand(outputDir + 'data/{osemosysFile}', osemosysFile = osemosysFiles),
		'config.yaml'
	output:
		expand(outputDir + scenarioName + '/data/{osemosysFile}', osemosysFile = osemosysFiles),
		outputDir + scenarioName + '/datapackage.json'
	conda:
		'envs/geoFilter.yaml'
	log:
		'logs/geographicFilter.log'
	shell:
		'python OPG_geographic_filter.py 2> {log}'

rule FileCheck:
	input: 
		expand('../../simplicity/data/{osemosysFile}', osemosysFile = osemosysFiles),
		inputDir + 'default_values.csv',
		'config.yaml'
	output:
		expand(outputDir + 'data/{missingFile}', missingFile = fileCheckFunc(osemosysFiles)),
		outputDir + 'data/default_values.csv'
	conda:
		'envs/fileCheck.yaml'
	log:
		'logs/fileCheck.log'
	shell:
		'python OPG_file_check.py 2> {log}'

rule otooleConvert:
	input:
		datapackage = outputDir + scenarioName + '/datapackage.json',
		csvFiles = expand(outputDir + scenarioName + '/data/{osemosysFile}', osemosysFile = osemosysFiles),
		defaultValueCsv = outputDir + 'data/default_values.csv'												 
	output:
		outputDir + scenarioName + '/' + scenarioName + '.txt'
	conda:
		'envs/otoole.yaml'
	log:
		'logs/otoole.log'
	shell:
		'otoole convert datapackage datafile {input.datapackage} {output} 2> {log}'

rule preProcess:
	input:
		outputDir + scenarioName + '/' + scenarioName + '.txt'
	output:
		outputDir + scenarioName + '/' + 'PreProcessed_' + scenarioName + '.txt'
	conda:
		'envs/preProcessData.yaml'
	log:
		'logs/preprocess.log'
	shell:
		'python ../../OSeMOSYS_GNU_MathProg/scripts/preprocess_data.py otoole {input} {output} 2> {log}'

rule createLP:
	input:
		modelFile = 'osemosys_fast_preprocessed.txt',
		dataFile = outputDir + scenarioName + '/' + 'PreProcessed_' + scenarioName + '.txt'
	output:
		outputDir + scenarioName + '/' + scenarioName + '.lp'
	log:
		'logs/createLP.log'
	shell:
		'glpsol -m {input.modelFile} -d {input.dataFile} --wlp {output} --check 2> {log}'

rule cbcSolve:
	input:
		outputDir + scenarioName + '/' + scenarioName + '.lp'
	output:
		outputDir + scenarioName + '/' + scenarioName + '.sol'
	log:
		'logs/cbcSolve.log'
	shell: 
		'cbc {input} solve -solu {output} 2> {log}'

rule postProcess:
	input:
		solutionFile = outputDir + scenarioName + '/' + scenarioName + '.sol',
		preProcessFile = outputDir + scenarioName + '/' + 'PreProcessed_' + scenarioName + '.txt'
	output:
		expand(outputDir + scenarioName + '/results/{resultFile}', resultFile = resultFiles),
	conda:
		'envs/otoole.yaml'
	log:
		'logs/postprocess.log'
	shell: 
		'otoole results cbc csv {input.solutionFile} {outputFolder} ' 
		'--input_datafile {input.preProcessFile} '
		'--input_datapackage {outputDir}{scenarioName}/datapackage.json ' 
		'2> {log}'

rule visualisation:
	input:
		expand(outputDir + scenarioName + '/results/{resultFile}', resultFile = resultFiles),
	output:
		expand(outputDir + scenarioName + '/figures/{resultFigure}.html', resultFigure = resultFigures),
    log:
        'logs/visualisation.log'
	shell: 
		'python visualisation.py'


#####################################
## CLEANING RULES
#####################################
rule cleanData:
	shell:
		'rm -rf {outputDir}data/*'

rule cleanFigs:
	shell:
		'rm -rf {outputDir}figs/*'

rule cleanDataFile:
	shell:
		'rm -rf {outputDir}{modelName}.txt'
